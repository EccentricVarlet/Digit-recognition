{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "    labels = []\n",
    "    mfccs = []\n",
    "\n",
    "    for f in os.listdir('recordings/'):\n",
    "        if f.endswith('.wav'):\n",
    "            wav, sr = librosa.load('recordings/' + f)\n",
    "            mfcc = librosa.feature.melspectrogram(wav)\n",
    "            \n",
    "            padded_mfcc = pad2d(mfcc,30)\n",
    "            mfccs.append(padded_mfcc)\n",
    "            label = f.split('_')[0]\n",
    "            labels.append(label)\n",
    "    return np.array(mfccs), to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(84, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all():\n",
    "    mfccs, labels = get_data()\n",
    "\n",
    "    dim_1 = mfccs.shape[1]\n",
    "    dim_2 = mfccs.shape[2]\n",
    "    channels = 1\n",
    "    classes = 10\n",
    "\n",
    "    X = mfccs\n",
    "    X = X.reshape((mfccs.shape[0], dim_1, dim_2, channels))\n",
    "    y = labels\n",
    "\n",
    "    input_shape = (dim_1, dim_2, channels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "    model = get_cnn_model(input_shape, classes)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,cnn_model = get_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1549, 128, 30, 1) (173, 128, 30, 1) (1549, 10) (173, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 127, 29, 64)       320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 127, 29, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 28, 48)       12336     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 126, 28, 48)       192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 125, 27, 84)       16212     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 125, 27, 84)       336       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 13, 84)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 62, 13, 84)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 67704)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8666240   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 8,705,566\n",
      "Trainable params: 8,704,790\n",
      "Non-trainable params: 776\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1394 samples, validate on 155 samples\n",
      "Epoch 1/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 2.4580 - accuracy: 0.2296 - val_loss: 2.2349 - val_accuracy: 0.2000\n",
      "Epoch 2/50\n",
      "1394/1394 [==============================] - 30s 21ms/step - loss: 1.7749 - accuracy: 0.3931 - val_loss: 2.0836 - val_accuracy: 0.2129\n",
      "Epoch 3/50\n",
      "1394/1394 [==============================] - 31s 22ms/step - loss: 1.4106 - accuracy: 0.5165 - val_loss: 2.1589 - val_accuracy: 0.2000\n",
      "Epoch 4/50\n",
      "1394/1394 [==============================] - 30s 22ms/step - loss: 1.1512 - accuracy: 0.6076 - val_loss: 2.1984 - val_accuracy: 0.1677\n",
      "Epoch 5/50\n",
      "1394/1394 [==============================] - 30s 21ms/step - loss: 0.9832 - accuracy: 0.6714 - val_loss: 2.2213 - val_accuracy: 0.1677\n",
      "Epoch 6/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.7934 - accuracy: 0.7461 - val_loss: 2.2616 - val_accuracy: 0.1742\n",
      "Epoch 7/50\n",
      "1394/1394 [==============================] - 33s 24ms/step - loss: 0.6592 - accuracy: 0.7841 - val_loss: 2.2727 - val_accuracy: 0.1742\n",
      "Epoch 8/50\n",
      "1394/1394 [==============================] - 31s 22ms/step - loss: 0.5411 - accuracy: 0.8422 - val_loss: 2.3240 - val_accuracy: 0.1677\n",
      "Epoch 9/50\n",
      "1394/1394 [==============================] - 35s 25ms/step - loss: 0.4777 - accuracy: 0.8572 - val_loss: 2.2956 - val_accuracy: 0.1677\n",
      "Epoch 10/50\n",
      "1394/1394 [==============================] - 36s 26ms/step - loss: 0.4390 - accuracy: 0.8737 - val_loss: 2.4152 - val_accuracy: 0.1806\n",
      "Epoch 11/50\n",
      "1394/1394 [==============================] - 36s 26ms/step - loss: 0.3247 - accuracy: 0.9154 - val_loss: 2.3449 - val_accuracy: 0.1806\n",
      "Epoch 12/50\n",
      "1394/1394 [==============================] - 39s 28ms/step - loss: 0.2686 - accuracy: 0.9369 - val_loss: 2.4973 - val_accuracy: 0.1613\n",
      "Epoch 13/50\n",
      "1394/1394 [==============================] - 35s 25ms/step - loss: 0.2521 - accuracy: 0.9254 - val_loss: 2.3803 - val_accuracy: 0.2000\n",
      "Epoch 14/50\n",
      "1394/1394 [==============================] - 33s 24ms/step - loss: 0.2103 - accuracy: 0.9469 - val_loss: 2.1055 - val_accuracy: 0.2129\n",
      "Epoch 15/50\n",
      "1394/1394 [==============================] - 36s 26ms/step - loss: 0.1880 - accuracy: 0.9613 - val_loss: 1.9043 - val_accuracy: 0.3097\n",
      "Epoch 16/50\n",
      "1394/1394 [==============================] - 34s 24ms/step - loss: 0.1839 - accuracy: 0.9541 - val_loss: 2.0685 - val_accuracy: 0.2323\n",
      "Epoch 17/50\n",
      "1394/1394 [==============================] - 36s 26ms/step - loss: 0.1376 - accuracy: 0.9692 - val_loss: 2.3272 - val_accuracy: 0.2516\n",
      "Epoch 18/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.1106 - accuracy: 0.9742 - val_loss: 2.4551 - val_accuracy: 0.2065\n",
      "Epoch 19/50\n",
      "1394/1394 [==============================] - 34s 25ms/step - loss: 0.1073 - accuracy: 0.9763 - val_loss: 1.8278 - val_accuracy: 0.3548\n",
      "Epoch 20/50\n",
      "1394/1394 [==============================] - 34s 25ms/step - loss: 0.0887 - accuracy: 0.9813 - val_loss: 1.7605 - val_accuracy: 0.4129\n",
      "Epoch 21/50\n",
      "1394/1394 [==============================] - 34s 24ms/step - loss: 0.0924 - accuracy: 0.9813 - val_loss: 1.7764 - val_accuracy: 0.3677\n",
      "Epoch 22/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0723 - accuracy: 0.9842 - val_loss: 1.7095 - val_accuracy: 0.4258\n",
      "Epoch 23/50\n",
      "1394/1394 [==============================] - 33s 24ms/step - loss: 0.0601 - accuracy: 0.9907 - val_loss: 1.6120 - val_accuracy: 0.5484\n",
      "Epoch 24/50\n",
      "1394/1394 [==============================] - 33s 23ms/step - loss: 0.0675 - accuracy: 0.9864 - val_loss: 1.4562 - val_accuracy: 0.4903\n",
      "Epoch 25/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0517 - accuracy: 0.9921 - val_loss: 1.3051 - val_accuracy: 0.5613\n",
      "Epoch 26/50\n",
      "1394/1394 [==============================] - 33s 23ms/step - loss: 0.0405 - accuracy: 0.9964 - val_loss: 1.5594 - val_accuracy: 0.4903\n",
      "Epoch 27/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0400 - accuracy: 0.9957 - val_loss: 1.7324 - val_accuracy: 0.4581\n",
      "Epoch 28/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0391 - accuracy: 0.9950 - val_loss: 1.3809 - val_accuracy: 0.5548\n",
      "Epoch 29/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0319 - accuracy: 0.9950 - val_loss: 1.3850 - val_accuracy: 0.5677\n",
      "Epoch 30/50\n",
      "1394/1394 [==============================] - 33s 23ms/step - loss: 0.0363 - accuracy: 0.9957 - val_loss: 1.3184 - val_accuracy: 0.5871\n",
      "Epoch 31/50\n",
      "1394/1394 [==============================] - 31s 23ms/step - loss: 0.0369 - accuracy: 0.9928 - val_loss: 1.3655 - val_accuracy: 0.5935\n",
      "Epoch 32/50\n",
      "1394/1394 [==============================] - 33s 24ms/step - loss: 0.0323 - accuracy: 0.9935 - val_loss: 1.3740 - val_accuracy: 0.6387\n",
      "Epoch 33/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0330 - accuracy: 0.9928 - val_loss: 1.1896 - val_accuracy: 0.6129\n",
      "Epoch 34/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0278 - accuracy: 0.9935 - val_loss: 1.3170 - val_accuracy: 0.6710\n",
      "Epoch 35/50\n",
      "1394/1394 [==============================] - 33s 23ms/step - loss: 0.0351 - accuracy: 0.9914 - val_loss: 1.4108 - val_accuracy: 0.6065\n",
      "Epoch 36/50\n",
      "1394/1394 [==============================] - 33s 23ms/step - loss: 0.0285 - accuracy: 0.9950 - val_loss: 1.9949 - val_accuracy: 0.4387\n",
      "Epoch 37/50\n",
      "1394/1394 [==============================] - 33s 24ms/step - loss: 0.0268 - accuracy: 0.9957 - val_loss: 1.7437 - val_accuracy: 0.5290\n",
      "Epoch 38/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0212 - accuracy: 0.9957 - val_loss: 1.4039 - val_accuracy: 0.6129\n",
      "Epoch 39/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0266 - accuracy: 0.9950 - val_loss: 1.3823 - val_accuracy: 0.6194\n",
      "Epoch 40/50\n",
      "1394/1394 [==============================] - 33s 23ms/step - loss: 0.0206 - accuracy: 0.9964 - val_loss: 1.2499 - val_accuracy: 0.6710\n",
      "Epoch 41/50\n",
      "1394/1394 [==============================] - 35s 25ms/step - loss: 0.0215 - accuracy: 0.9950 - val_loss: 1.5185 - val_accuracy: 0.6387\n",
      "Epoch 42/50\n",
      "1394/1394 [==============================] - 33s 24ms/step - loss: 0.0221 - accuracy: 0.9943 - val_loss: 1.6920 - val_accuracy: 0.5742\n",
      "Epoch 43/50\n",
      "1394/1394 [==============================] - 33s 24ms/step - loss: 0.0169 - accuracy: 0.9971 - val_loss: 1.3846 - val_accuracy: 0.6000\n",
      "Epoch 44/50\n",
      "1394/1394 [==============================] - 35s 25ms/step - loss: 0.0144 - accuracy: 0.9986 - val_loss: 1.4432 - val_accuracy: 0.6839\n",
      "Epoch 45/50\n",
      "1394/1394 [==============================] - 34s 24ms/step - loss: 0.0147 - accuracy: 0.9978 - val_loss: 1.4963 - val_accuracy: 0.6000\n",
      "Epoch 46/50\n",
      "1394/1394 [==============================] - 33s 24ms/step - loss: 0.0176 - accuracy: 0.9971 - val_loss: 2.5727 - val_accuracy: 0.2452\n",
      "Epoch 47/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0125 - accuracy: 0.9986 - val_loss: 1.4108 - val_accuracy: 0.6258\n",
      "Epoch 48/50\n",
      "1394/1394 [==============================] - 33s 24ms/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 1.3833 - val_accuracy: 0.6323\n",
      "Epoch 49/50\n",
      "1394/1394 [==============================] - 32s 23ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 1.4268 - val_accuracy: 0.6839\n",
      "Epoch 50/50\n",
      "1394/1394 [==============================] - 33s 24ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 2.7648 - val_accuracy: 0.4581\n"
     ]
    }
   ],
   "source": [
    "keras_callback = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1,\n",
    "                                             write_graph=True, write_images=True)\n",
    "\n",
    "cnn_model.fit(X_train, y_train, batch_size=64, epochs=50, verbose=1, validation_split=0.1, callbacks=[keras_callback])\n",
    "\n",
    "cnn_model.save('trained_model_mel.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module keras.engine.training:\n",
      "\n",
      "fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs) method of keras.engine.sequential.Sequential instance\n",
      "    Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      "    \n",
      "    # Arguments\n",
      "        x: Input data. It could be:\n",
      "            - A Numpy array (or array-like), or a list of arrays\n",
      "              (in case the model has multiple inputs).\n",
      "            - A dict mapping input names to the corresponding\n",
      "              array/tensors, if the model has named inputs.\n",
      "            - A generator or `keras.utils.Sequence` returning\n",
      "              `(inputs, targets)` or `(inputs, targets, sample weights)`.\n",
      "            - None (default) if feeding from framework-native\n",
      "              tensors (e.g. TensorFlow data tensors).\n",
      "        y: Target data. Like the input data `x`,\n",
      "            it could be either Numpy array(s), framework-native tensor(s),\n",
      "            list of Numpy arrays (if the model has multiple outputs) or\n",
      "            None (default) if feeding from framework-native tensors\n",
      "            (e.g. TensorFlow data tensors).\n",
      "            If output layers in the model are named, you can also pass a\n",
      "            dictionary mapping output names to Numpy arrays.\n",
      "            If `x` is a generator, or `keras.utils.Sequence` instance,\n",
      "            `y` should not be specified (since targets will be obtained\n",
      "            from `x`).\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of symbolic tensors, generators, or `Sequence` instances\n",
      "            (since they generate batches).\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire `x` and `y`\n",
      "            data provided.\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training and validation\n",
      "            (if ).\n",
      "            See [callbacks](/callbacks).\n",
      "        validation_split: Float between 0 and 1.\n",
      "            Fraction of the training data to be used as validation data.\n",
      "            The model will set apart this fraction of the training data,\n",
      "            will not train on it, and will evaluate\n",
      "            the loss and any model metrics\n",
      "            on this data at the end of each epoch.\n",
      "            The validation data is selected from the last samples\n",
      "            in the `x` and `y` data provided, before shuffling.\n",
      "            This argument is not supported when `x` is a generator or\n",
      "            `Sequence` instance.\n",
      "        validation_data: Data on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data.\n",
      "            `validation_data` will override `validation_split`.\n",
      "            `validation_data` could be:\n",
      "                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      "                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      "                - dataset or a dataset iterator\n",
      "            For the first two cases, `batch_size` must be provided.\n",
      "            For the last case, `validation_steps` must be provided.\n",
      "        shuffle: Boolean (whether to shuffle the training data\n",
      "            before each epoch) or str (for 'batch').\n",
      "            'batch' is a special option for dealing with the\n",
      "            limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      "            Has no effect when `steps_per_epoch` is not `None`.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only).\n",
      "            This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples from\n",
      "            an under-represented class.\n",
      "        sample_weight: Optional Numpy array of weights for\n",
      "            the training samples, used for weighting the loss function\n",
      "            (during training only). You can either pass a flat (1D)\n",
      "            Numpy array with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples),\n",
      "            or in the case of temporal data,\n",
      "            you can pass a 2D array with shape\n",
      "            `(samples, sequence_length)`,\n",
      "            to apply a different weight to every timestep of every sample.\n",
      "            In this case you should make sure to specify\n",
      "            `sample_weight_mode=\"temporal\"` in `compile()`. This argument\n",
      "            is not supported when `x` generator, or `Sequence` instance,\n",
      "            instead provide the sample_weights as the third element of `x`.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "        steps_per_epoch: Integer or `None`.\n",
      "            Total number of steps (batches of samples)\n",
      "            before declaring one epoch finished and starting the\n",
      "            next epoch. When training with input tensors such as\n",
      "            TensorFlow data tensors, the default `None` is equal to\n",
      "            the number of samples in your dataset divided by\n",
      "            the batch size, or 1 if that cannot be determined.\n",
      "        validation_steps: Only relevant if `steps_per_epoch`\n",
      "            is specified. Total number of steps (batches of samples)\n",
      "            to validate before stopping.\n",
      "        validation_steps: Only relevant if `validation_data` is provided\n",
      "            and is a generator. Total number of steps (batches of samples)\n",
      "            to draw before stopping when performing validation at the end\n",
      "            of every epoch.\n",
      "        validation_freq: Only relevant if validation data is provided. Integer\n",
      "            or list/tuple/set. If an integer, specifies how many training\n",
      "            epochs to run before a new validation run is performed, e.g.\n",
      "            `validation_freq=2` runs validation every 2 epochs. If a list,\n",
      "            tuple, or set, specifies the epochs on which to run validation,\n",
      "            e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n",
      "            of the 1st, 2nd, and 10th epochs.\n",
      "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "            input only. Maximum size for the generator queue.\n",
      "            If unspecified, `max_queue_size` will default to 10.\n",
      "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "            only. Maximum number of processes to spin up\n",
      "            when using process-based threading. If unspecified, `workers`\n",
      "            will default to 1. If 0, will execute the generator on the main\n",
      "            thread.\n",
      "        use_multiprocessing: Boolean. Used for generator or\n",
      "            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "            threading. If unspecified, `use_multiprocessing` will default to\n",
      "            `False`. Note that because this implementation relies on\n",
      "            multiprocessing, you should not pass non-picklable arguments to\n",
      "            the generator as they can't be passed easily to children processes.\n",
      "        **kwargs: Used for backwards compatibility.\n",
      "    \n",
      "    # Returns\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "    \n",
      "    # Raises\n",
      "        RuntimeError: If the model was never compiled.\n",
      "        ValueError: In case of mismatch between the provided input data\n",
      "            and what the model expects.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cnn_model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_preds(X, y):\n",
    "    trained_model = keras.models.load_model('trained_model_mel.h5')\n",
    "    predictions = trained_model.predict_classes(X)\n",
    "\n",
    "    print(classification_report(y, to_categorical(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71        23\n",
      "           1       1.00      0.42      0.59        19\n",
      "           2       0.75      0.45      0.56        20\n",
      "           3       1.00      0.53      0.69        19\n",
      "           4       0.48      0.48      0.48        21\n",
      "           5       0.22      0.87      0.35        15\n",
      "           6       0.55      0.55      0.55        11\n",
      "           7       0.47      0.64      0.55        14\n",
      "           8       1.00      0.28      0.43        18\n",
      "           9       1.00      0.38      0.56        13\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       173\n",
      "   macro avg       0.72      0.53      0.55       173\n",
      "weighted avg       0.73      0.53      0.55       173\n",
      " samples avg       0.53      0.53      0.53       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_preds(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5260115606936416"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "y_pred = (trained_model.predict_classes(X_test))\n",
    "accuracy_score(np.argmax(y_test,axis=1), y_pred)\n",
    "# #print(np.argmax(y_test,axis=1),y_pred.shape)\n",
    "# np.argmax(y_test,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = keras.models.load_model('trained_model_mel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record sound for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import sounddevice as sd\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import os, sys, subprocess\n",
    "import numpy as np\n",
    "import json\n",
    "import tkinter as tk\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from tkinter import messagebox\n",
    "import tkinter.font as font\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "root.geometry(\"720x600\")\n",
    "root.configure(background='white')\n",
    "root.title(\"Testing\")\n",
    "\n",
    "myFont = font.Font(family='sans-serif')\n",
    "\n",
    "def record():\n",
    "    global data\n",
    "    fs = 44100  \n",
    "    seconds = .75\n",
    "    myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=2)\n",
    "    sd.wait()\n",
    "    data =  myrecording\n",
    "\n",
    "def play():\n",
    "    global update,fr\n",
    "    write('/home/incentive/Videos/Group Project/Digit Recognition/test record/' +  'temp'+'.wav', 44100, data)\n",
    "    audio_data, sampling_rate = librosa.load('/home/incentive/Videos/Group Project/Digit Recognition/test record/'+'temp.wav')\n",
    "    noisy_part = audio_data[10000:15000]  \n",
    "    reduced_noise = nr.reduce_noise(audio_clip=audio_data, noise_clip=noisy_part, verbose=False)\n",
    "    update = reduced_noise\n",
    "    fr=sampling_rate\n",
    "    sd.play(reduced_noise,sampling_rate)\n",
    "    sd.wait(6)\n",
    "    \n",
    "def popupmsg(msg):\n",
    "    popup = tk.Toplevel(root)\n",
    "    popup.configure(background='white')\n",
    "    popup.geometry(\"300x300\")\n",
    "    popup.wm_title(\"Prediction\")\n",
    "    popup.tkraise(root) # This just tells the message to be on top of the root window.\n",
    "    tk.Label(popup, text=msg,   bg='white',fg = \"Red\", font = \"arial 50 bold italic\").pack(side=\"top\", fill=\"x\", pady=50)\n",
    "    tk.Button(popup, text=\"Thank You!\", bg=\"cyan\",height=2,width=10,\n",
    "              font = \"Helvetica 30 bold italic\",command = popup.destroy).pack()\n",
    "    \n",
    "def check():\n",
    "    pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "    mfcc = librosa.feature.melspectrogram(update)\n",
    "    padded_mfcc = pad2d(mfcc,30)\n",
    "    data = padded_mfcc.reshape(1,padded_mfcc.shape[0],padded_mfcc.shape[1],1) \n",
    "    predictions = trained_model.predict_classes(data)\n",
    "    popupmsg(str(predictions.item()))\n",
    "    \n",
    "\n",
    "\n",
    "label_dict = json.load(open(\"label.txt\"))\n",
    "\n",
    "tk.Label(root, \n",
    "\t\t text=\"Testing Digit Recognizer\",\n",
    "\t\t fg = \"Red\",\n",
    "         bg='white',\n",
    "\t\t font = \"arial 30 bold italic\").pack(pady=20)\n",
    "\n",
    "record_button = Button(root, text=\"Start record\",bg=\"blue\", command=record,height=3,width=20,font = \"Helvetica 30 bold italic\").pack(pady=10)\n",
    "\n",
    "play_button = Button(root, text=\"Play\",bg=\"red\", command=play,height=3,width=20,font = \"Helvetica 30 bold italic\").pack(pady=10)\n",
    "check_button = Button(root, text=\"Predict\",bg=\"green\", command=check,height=3,width=20,font = \"Helvetica 30 bold italic\").pack(pady=10)\n",
    "\n",
    "root.mainloop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
