{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package.\n",
    "\n",
    "     -Required Package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "    labels = []\n",
    "    mfccs = []\n",
    "\n",
    "    for f in os.listdir('recordings/'):\n",
    "        if f.endswith('.wav'):\n",
    "            wav, sr = librosa.load('recordings/' + f)\n",
    "            mfcc = librosa.feature.mfcc(wav)\n",
    "            padded_mfcc = pad2d(mfcc,40)\n",
    "            mfccs.append(padded_mfcc)\n",
    "            label = f.split('_')[0]\n",
    "            labels.append(label)\n",
    "    return np.array(mfccs), to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(84, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    \n",
    "    model.add(Conv2D(164, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all():\n",
    "    mfccs, labels = get_data()\n",
    "\n",
    "    dim_1 = mfccs.shape[1]\n",
    "    dim_2 = mfccs.shape[2]\n",
    "    channels = 1\n",
    "    classes = 10\n",
    "\n",
    "    X = mfccs\n",
    "    X = X.reshape((mfccs.shape[0], dim_1, dim_2, channels))\n",
    "    y = labels\n",
    "\n",
    "    input_shape = (dim_1, dim_2, channels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "    model = get_cnn_model(input_shape, classes)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,cnn_model = get_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1549, 20, 40, 1) (173, 20, 40, 1) (1549, 10) (173, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 19, 39, 64)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 19, 39, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 38, 48)        12336     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 18, 38, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 37, 84)        16212     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 37, 84)        336       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 36, 164)       55268     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 36, 164)       656       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 18, 164)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 18, 164)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 23616)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3022976   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 48)                192       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                490       \n",
      "=================================================================\n",
      "Total params: 3,121,378\n",
      "Trainable params: 3,120,178\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1394 samples, validate on 155 samples\n",
      "Epoch 1/50\n",
      "1394/1394 [==============================] - 25s 18ms/step - loss: 2.2701 - accuracy: 0.2633 - val_loss: 2.5517 - val_accuracy: 0.2000\n",
      "Epoch 2/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 1.4886 - accuracy: 0.4692 - val_loss: 1.7616 - val_accuracy: 0.4903\n",
      "Epoch 3/50\n",
      "1394/1394 [==============================] - 22s 15ms/step - loss: 1.1791 - accuracy: 0.5890 - val_loss: 1.7472 - val_accuracy: 0.4516\n",
      "Epoch 4/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.9257 - accuracy: 0.6966 - val_loss: 1.7010 - val_accuracy: 0.4645\n",
      "Epoch 5/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.7304 - accuracy: 0.7834 - val_loss: 1.7285 - val_accuracy: 0.3806\n",
      "Epoch 6/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.6072 - accuracy: 0.8293 - val_loss: 1.6318 - val_accuracy: 0.4452\n",
      "Epoch 7/50\n",
      "1394/1394 [==============================] - 19s 14ms/step - loss: 0.5282 - accuracy: 0.8522 - val_loss: 1.3066 - val_accuracy: 0.5806\n",
      "Epoch 8/50\n",
      "1394/1394 [==============================] - 23s 17ms/step - loss: 0.4235 - accuracy: 0.8831 - val_loss: 1.1204 - val_accuracy: 0.6129\n",
      "Epoch 9/50\n",
      "1394/1394 [==============================] - 23s 16ms/step - loss: 0.3310 - accuracy: 0.9075 - val_loss: 1.1350 - val_accuracy: 0.6774\n",
      "Epoch 10/50\n",
      "1394/1394 [==============================] - 23s 17ms/step - loss: 0.2769 - accuracy: 0.9362 - val_loss: 1.2814 - val_accuracy: 0.6000\n",
      "Epoch 11/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.2658 - accuracy: 0.9426 - val_loss: 0.7135 - val_accuracy: 0.7742\n",
      "Epoch 12/50\n",
      "1394/1394 [==============================] - 24s 17ms/step - loss: 0.1911 - accuracy: 0.9591 - val_loss: 0.8517 - val_accuracy: 0.7484\n",
      "Epoch 13/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.1852 - accuracy: 0.9598 - val_loss: 0.6064 - val_accuracy: 0.8323\n",
      "Epoch 14/50\n",
      "1394/1394 [==============================] - 18s 13ms/step - loss: 0.1569 - accuracy: 0.9670 - val_loss: 0.5626 - val_accuracy: 0.8194\n",
      "Epoch 15/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.1339 - accuracy: 0.9706 - val_loss: 0.7776 - val_accuracy: 0.7806\n",
      "Epoch 16/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.1168 - accuracy: 0.9756 - val_loss: 0.5057 - val_accuracy: 0.8581\n",
      "Epoch 17/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.1084 - accuracy: 0.9785 - val_loss: 0.4513 - val_accuracy: 0.8387\n",
      "Epoch 18/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.0990 - accuracy: 0.9756 - val_loss: 0.7735 - val_accuracy: 0.8129\n",
      "Epoch 19/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.0850 - accuracy: 0.9821 - val_loss: 0.5734 - val_accuracy: 0.8065\n",
      "Epoch 20/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.0892 - accuracy: 0.9778 - val_loss: 0.4668 - val_accuracy: 0.8710\n",
      "Epoch 21/50\n",
      "1394/1394 [==============================] - 18s 13ms/step - loss: 0.0753 - accuracy: 0.9813 - val_loss: 0.3412 - val_accuracy: 0.8839\n",
      "Epoch 22/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.0837 - accuracy: 0.9799 - val_loss: 0.3386 - val_accuracy: 0.8774\n",
      "Epoch 23/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.0616 - accuracy: 0.9864 - val_loss: 0.7569 - val_accuracy: 0.7613\n",
      "Epoch 24/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.0713 - accuracy: 0.9813 - val_loss: 0.5596 - val_accuracy: 0.8452\n",
      "Epoch 25/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.0557 - accuracy: 0.9907 - val_loss: 0.4181 - val_accuracy: 0.8452\n",
      "Epoch 26/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.0510 - accuracy: 0.9914 - val_loss: 0.3885 - val_accuracy: 0.8710\n",
      "Epoch 27/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.0422 - accuracy: 0.9928 - val_loss: 0.3463 - val_accuracy: 0.8774\n",
      "Epoch 28/50\n",
      "1394/1394 [==============================] - 20s 14ms/step - loss: 0.0446 - accuracy: 0.9900 - val_loss: 0.3667 - val_accuracy: 0.8710\n",
      "Epoch 29/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.0487 - accuracy: 0.9900 - val_loss: 0.4912 - val_accuracy: 0.8645\n",
      "Epoch 30/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.0478 - accuracy: 0.9907 - val_loss: 0.4773 - val_accuracy: 0.8581\n",
      "Epoch 31/50\n",
      "1394/1394 [==============================] - 23s 16ms/step - loss: 0.0599 - accuracy: 0.9828 - val_loss: 1.2643 - val_accuracy: 0.6581\n",
      "Epoch 32/50\n",
      "1394/1394 [==============================] - 23s 16ms/step - loss: 0.0583 - accuracy: 0.9821 - val_loss: 0.4950 - val_accuracy: 0.8452\n",
      "Epoch 33/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.0375 - accuracy: 0.9900 - val_loss: 0.5483 - val_accuracy: 0.8323\n",
      "Epoch 34/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.0349 - accuracy: 0.9914 - val_loss: 0.3981 - val_accuracy: 0.8516\n",
      "Epoch 35/50\n",
      "1394/1394 [==============================] - 19s 14ms/step - loss: 0.0284 - accuracy: 0.9935 - val_loss: 0.5722 - val_accuracy: 0.8387\n",
      "Epoch 36/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.0293 - accuracy: 0.9928 - val_loss: 0.5093 - val_accuracy: 0.8774\n",
      "Epoch 37/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.0231 - accuracy: 0.9935 - val_loss: 0.4947 - val_accuracy: 0.8387\n",
      "Epoch 38/50\n",
      "1394/1394 [==============================] - 21s 15ms/step - loss: 0.0281 - accuracy: 0.9957 - val_loss: 0.5955 - val_accuracy: 0.8516\n",
      "Epoch 39/50\n",
      "1394/1394 [==============================] - 23s 17ms/step - loss: 0.0356 - accuracy: 0.9892 - val_loss: 0.6014 - val_accuracy: 0.8516\n",
      "Epoch 40/50\n",
      "1394/1394 [==============================] - 23s 16ms/step - loss: 0.0270 - accuracy: 0.9943 - val_loss: 0.5445 - val_accuracy: 0.8645\n",
      "Epoch 41/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.0207 - accuracy: 0.9957 - val_loss: 0.4286 - val_accuracy: 0.8839\n",
      "Epoch 42/50\n",
      "1394/1394 [==============================] - 18s 13ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.5170 - val_accuracy: 0.8516\n",
      "Epoch 43/50\n",
      "1394/1394 [==============================] - 23s 17ms/step - loss: 0.0262 - accuracy: 0.9957 - val_loss: 0.5301 - val_accuracy: 0.8581\n",
      "Epoch 44/50\n",
      "1394/1394 [==============================] - 25s 18ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.3850 - val_accuracy: 0.8774\n",
      "Epoch 45/50\n",
      "1394/1394 [==============================] - 26s 18ms/step - loss: 0.0180 - accuracy: 0.9964 - val_loss: 0.5540 - val_accuracy: 0.8387\n",
      "Epoch 46/50\n",
      "1394/1394 [==============================] - 23s 16ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.4675 - val_accuracy: 0.8839\n",
      "Epoch 47/50\n",
      "1394/1394 [==============================] - 23s 16ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.4270 - val_accuracy: 0.8774\n",
      "Epoch 48/50\n",
      "1394/1394 [==============================] - 23s 16ms/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.5673 - val_accuracy: 0.8516\n",
      "Epoch 49/50\n",
      "1394/1394 [==============================] - 20s 14ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.4863 - val_accuracy: 0.8516\n",
      "Epoch 50/50\n",
      "1394/1394 [==============================] - 22s 16ms/step - loss: 0.0185 - accuracy: 0.9971 - val_loss: 0.4410 - val_accuracy: 0.8710\n"
     ]
    }
   ],
   "source": [
    "keras_callback = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1,\n",
    "                                             write_graph=True, write_images=True)\n",
    "\n",
    "cnn_model.fit(X_train, y_train, batch_size=64, epochs=50, verbose=1, validation_split=0.1, callbacks=[keras_callback])\n",
    "\n",
    "cnn_model.save('trained_model_new.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_preds(X, y):\n",
    "    trained_model = keras.models.load_model('trained_model_new.h5')\n",
    "    predictions = trained_model.predict_classes(X)\n",
    "\n",
    "    print(classification_report(y, to_categorical(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       0.86      0.95      0.90        19\n",
      "           2       0.95      0.90      0.92        20\n",
      "           3       1.00      1.00      1.00        19\n",
      "           4       0.95      0.95      0.95        21\n",
      "           5       0.88      0.93      0.90        15\n",
      "           6       1.00      0.82      0.90        11\n",
      "           7       1.00      0.93      0.96        14\n",
      "           8       0.94      0.89      0.91        18\n",
      "           9       0.80      0.92      0.86        13\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       173\n",
      "   macro avg       0.94      0.93      0.93       173\n",
      "weighted avg       0.94      0.94      0.94       173\n",
      " samples avg       0.94      0.94      0.94       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_preds(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9364161849710982"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "y_pred = (trained_model.predict_classes(X_test))\n",
    "accuracy_score(np.argmax(y_test,axis=1), y_pred)\n",
    "# #print(np.argmax(y_test,axis=1),y_pred.shape)\n",
    "# np.argmax(y_test,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = keras.models.load_model('trained_model_new.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record sound for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import sounddevice as sd\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import os, sys, subprocess\n",
    "import numpy as np\n",
    "import json\n",
    "import tkinter as tk\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from tkinter import messagebox\n",
    "import tkinter.font as font\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "root.geometry(\"720x600\")\n",
    "root.configure(background='white')\n",
    "root.title(\"Testing\")\n",
    "\n",
    "myFont = font.Font(family='sans-serif')\n",
    "\n",
    "def record():\n",
    "    global data\n",
    "    fs = 44100  \n",
    "    seconds = .75\n",
    "    myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=2)\n",
    "    sd.wait()\n",
    "    data =  myrecording\n",
    "\n",
    "def play():\n",
    "    global update,fr\n",
    "    write('/home/incentive/Videos/Group Project/Digit Recognition/test record/' +  'temp'+'.wav', 44100, data)\n",
    "    audio_data, sampling_rate = librosa.load('/home/incentive/Videos/Group Project/Digit Recognition/test record/'+'temp.wav')\n",
    "    noisy_part = audio_data[10000:15000]  \n",
    "    reduced_noise = nr.reduce_noise(audio_clip=audio_data, noise_clip=noisy_part, verbose=False)\n",
    "    update = reduced_noise\n",
    "    fr=sampling_rate\n",
    "    sd.play(reduced_noise,sampling_rate)\n",
    "    sd.wait(6)\n",
    "    \n",
    "def popupmsg(msg):\n",
    "    popup = tk.Toplevel(root)\n",
    "    popup.configure(background='white')\n",
    "    popup.geometry(\"300x300\")\n",
    "    popup.wm_title(\"Prediction\")\n",
    "    popup.tkraise(root) # This just tells the message to be on top of the root window.\n",
    "    tk.Label(popup, text=msg,   bg='white',fg = \"Red\", font = \"arial 50 bold italic\").pack(side=\"top\", fill=\"x\", pady=50)\n",
    "    tk.Button(popup, text=\"Thank You!\", bg=\"cyan\",height=2,width=10,\n",
    "              font = \"Helvetica 30 bold italic\",command = popup.destroy).pack()\n",
    "    \n",
    "def check():\n",
    "    pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "    mfcc = librosa.feature.mfcc(update)\n",
    "    padded_mfcc = pad2d(mfcc,40)\n",
    "    data = padded_mfcc.reshape(1,padded_mfcc.shape[0],padded_mfcc.shape[1],1) \n",
    "    predictions = trained_model.predict_classes(data)\n",
    "    popupmsg(str(predictions.item()))\n",
    "    \n",
    "\n",
    "\n",
    "label_dict = json.load(open(\"label.txt\"))\n",
    "\n",
    "tk.Label(root, \n",
    "\t\t text=\"Testing Digit Recognizer\",\n",
    "\t\t fg = \"Red\",\n",
    "         bg='white',\n",
    "\t\t font = \"arial 30 bold italic\").pack(pady=20)\n",
    "\n",
    "record_button = Button(root, text=\"Start record\",bg=\"blue\", command=record,height=3,width=20,font = \"Helvetica 30 bold italic\").pack(pady=10)\n",
    "\n",
    "play_button = Button(root, text=\"Play\",bg=\"red\", command=play,height=3,width=20,font = \"Helvetica 30 bold italic\").pack(pady=10)\n",
    "check_button = Button(root, text=\"Predict\",bg=\"green\", command=check,height=3,width=20,font = \"Helvetica 30 bold italic\").pack(pady=10)\n",
    "\n",
    "root.mainloop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
