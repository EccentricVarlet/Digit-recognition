{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/incentive/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io.wavfile import write\n",
    "import cv2\n",
    "import sounddevice as sd\n",
    "import IPython.display as ipd\n",
    "import noisereduce as nr\n",
    "\n",
    "EPS = 1e-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(wav):\n",
    "    D = librosa.stft(wav, n_fft=480, hop_length=160,\n",
    "                     win_length=480, window='hamming')\n",
    "    spect, phase = librosa.magphase(D)\n",
    "    return spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'recordings/'+'0_tuli_2.wav'\n",
    "wav, sr = librosa.load(file_path, sr=None)\n",
    "print(wav.shape, wav.max(), wav.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(wav, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation():\n",
    "    for f in os.listdir('recordings/'):\n",
    "        if f.endswith('.wav'):\n",
    "            name = f.replace('.wav','')\n",
    "            print(f)\n",
    "            wav, sr = librosa.load('recordings/' + f)\n",
    "            speed_rate = np.random.uniform(0.7,1.3)\n",
    "            wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "            print('speed rate: %.3f' % speed_rate, '(lower is faster)')\n",
    "            if len(wav_speed_tune) < 16000:\n",
    "                pad_len = 16000 - len(wav_speed_tune)\n",
    "                wav_speed_tune = np.r_[np.random.uniform(-0.001,0.001,int(pad_len/2)),\n",
    "                           wav_speed_tune,\n",
    "                           np.random.uniform(-0.001,0.001,int(np.ceil(pad_len/2)))]\n",
    "            else: \n",
    "                cut_len = len(wav_speed_tune) - 16000\n",
    "                wav_speed_tune = wav_speed_tune[int(cut_len/2):int(cut_len/2)+16000]\n",
    "#             sd.play(wav,sr)\n",
    "#             sd.wait(5)\n",
    "            print('wav length: ', wav_speed_tune.shape[0])\n",
    "            write('data collect/' +name+'_speed'+'.wav', sr,wav_speed_tune)\n",
    "            \n",
    "# augmentation()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_atik_8.wav\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (11025,) (9759,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-647fd2b4d269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0maugmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-647fd2b4d269>\u001b[0m in \u001b[0;36maugmentation\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mbg_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstart_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m16666\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mwav_with_bg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m               \u001b[0mbg_slice\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mnoisy_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav_with_bg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_with_bg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (11025,) (9759,) "
     ]
    }
   ],
   "source": [
    "def augmentation():\n",
    "    for f in os.listdir('recordings/'):\n",
    "        if f.endswith('.wav'):\n",
    "            name = f.replace('.wav','')\n",
    "            print(f)\n",
    "            wav, sr = librosa.load('recordings/'+f)\n",
    "            bg, sr = librosa.load('test record/'+ 'audio.wav')\n",
    "            start_ = np.random.randint(bg.shape[0])\n",
    "            bg_slice = bg[start_ : start_+16666]\n",
    "            wav_with_bg = wav * np.random.uniform(0.8, 1.2) + \\\n",
    "              bg_slice * np.random.uniform(0, 0.1)\n",
    "            noisy_part = wav_with_bg[10000:15000] \n",
    "            sd.play(wav_with_bg)\n",
    "#             reduced_noise = nr.reduce_noise(audio_clip=wav_with_bg, noise_clip=noisy_part, verbose=False)\n",
    "#             sd.play(reduced_noise,sr)\n",
    "#             sd.wait(5)\n",
    "#             ipd.Audio(wav_with_bg, rate=sr) \n",
    "\n",
    "            \n",
    "            \n",
    "augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16538,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav, sr = librosa.load('test record/'+'audio.wav')\n",
    "sd.play(wav,sr)\n",
    "wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav, sr = librosa.load('recordings/'+'6_adeeb_7_speed.wav')\n",
    "sd.play(wav,sr)\n",
    "wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.120081668138703"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(0.8, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from utils import wav2mfcc, model, get_data\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data():\n",
    "    pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "    labels = []\n",
    "    mfccs = []\n",
    "\n",
    "    for f in os.listdir('recordings/'):\n",
    "        if f.endswith('.wav'):\n",
    "            wav, sr = librosa.load('recordings/' + f)\n",
    "            mfcc = librosa.feature.mfcc(wav)\n",
    "            padded_mfcc = pad2d(mfcc,40)\n",
    "            mfccs.append(padded_mfcc)\n",
    "            label = f.split('_')[0]\n",
    "            labels.append(label)\n",
    "    return np.array(mfccs), to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a,b = get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#b.shape,a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all():\n",
    "    mfccs, labels = get_data()\n",
    "\n",
    "    dim_1 = mfccs.shape[1]\n",
    "    dim_2 = mfccs.shape[2]\n",
    "    channels = 1\n",
    "    classes = 10\n",
    "\n",
    "    X = mfccs\n",
    "    X = X.reshape((mfccs.shape[0], dim_1, dim_2, channels))\n",
    "    y = labels\n",
    "\n",
    "    input_shape = (dim_1, dim_2, channels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "    model = get_cnn_model(input_shape, classes)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,cnn_model = get_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_callback = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1,\n",
    "                                             write_graph=True, write_images=True)\n",
    "\n",
    "cnn_model.fit(X_train, y_train, batch_size=64, epochs=50, verbose=1, validation_split=0.1, callbacks=[keras_callback])\n",
    "\n",
    "cnn_model.save('trained_model_new.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_preds(X, y):\n",
    "    trained_model = keras.models.load_model('trained_model_new.h5')\n",
    "    predictions = trained_model.predict_classes(X)\n",
    "\n",
    "    print(classification_report(y, to_categorical(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_preds(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "wav, sr = librosa.load('3_atik_34.wav')\n",
    "sd.play(wav,sr)\n",
    "pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "mfcc = librosa.feature.mfcc(wav)\n",
    "padded_mfcc = pad2d(mfcc,40)\n",
    "data = padded_mfcc.reshape(1,padded_mfcc.shape[0],padded_mfcc.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = keras.models.load_model('trained_model_new.h5')\n",
    "predictions = trained_model.predict_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "import random as rn\n",
    "random_file = rn.choice(os.listdir('recordings'))\n",
    "print(random_file)\n",
    "# mfccs.append(padded_mfcc)\n",
    "wav, sr = librosa.load('recordings/' + '3_atik_31.wav')\n",
    "mfcc = librosa.feature.mfcc(wav)\n",
    "padded_mfcc = pad2d(mfcc,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = padded_mfcc.shape[0]\n",
    "c  = padded_mfcc.shape[1]\n",
    "r,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = padded_mfcc.reshape(1,r,c,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = keras.models.load_model('trained_model_new.h5')\n",
    "predictions = trained_model.predict_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "wav, sr = librosa.load('recordings/' + '8_atik_01.wav')\n",
    "mfcc = librosa.feature.mfcc(wav)\n",
    "padded_mfcc = pad2d(mfcc,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = padded_mfcc.reshape(1,padded_mfcc.shape[0],padded_mfcc.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_model = keras.models.load_model('trained_model_new.h5')\n",
    "predictions = trained_model.predict_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "sd.play(wav,24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import noisereduce as nr\n",
    "# audio_data, sampling_rate = librosa.load('recordings/'+'temp.wav')\n",
    "# noisy_part = audio_data[0:22000]  \n",
    "# reduced_noise = nr.reduce_noise(audio_clip=audio_data, noise_clip=noisy_part, verbose=False)\n",
    "# librosa.output.write_wav('8_atik_01.wav', reduced_noise, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = librosa.load('recordings/'+'8_atik_01.wav')\n",
    "sd.play(wav,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from utils import wav2mfcc, model, get_data\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "wav, sr = librosa.load('recordings/'+'3_atik_31.wav')\n",
    "sd.play(wav,sr)\n",
    "pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))\n",
    "mfcc = librosa.feature.mfcc(wav)\n",
    "padded_mfcc = pad2d(mfcc,40)\n",
    "data = padded_mfcc.reshape(1,padded_mfcc.shape[0],padded_mfcc.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = keras.models.load_model('trained_model_new.h5')\n",
    "predictions = trained_model.predict_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
